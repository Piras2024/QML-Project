{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Piras2024/QML-Project/blob/main/CIFAR_10_QNL_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit==1.4.2\n",
        "import qiskit\n",
        "print(qiskit.__version__)"
      ],
      "metadata": {
        "id": "Krp52fIclKYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CHOOSE BINARY OR MULTICLASS CLASSIFICATION\n",
        "set 0 for binary classificatio 1 for multiclass classification"
      ],
      "metadata": {
        "id": "77Xb_VeW7h9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multiclassClassification = 1"
      ],
      "metadata": {
        "id": "wrNIo52i7uIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PQC DEFINITION"
      ],
      "metadata": {
        "id": "I7rTQUvTAj9C"
      }
    },
    {
      "source": [
        "from qiskit import QuantumCircuit\n",
        "from qiskit.circuit import Parameter\n",
        "\n",
        "\n",
        "class QNLNetCircuit:\n",
        "    def __init__(self, num_qubits=4, ansatz=0, ansatz_reps=1):\n",
        "        \"\"\"\n",
        "        QNLNNCircuit class implements a quantum circuit\n",
        "        for a non-local neural network.\n",
        "\n",
        "        Args:\n",
        "             num_qubits: The number of qubit used in the circuit. It is fixed\n",
        "                to be 4 qubits for this circuit implementation.\n",
        "        \"\"\"\n",
        "        self.ansatz = ansatz\n",
        "        self.ansatz_reps = ansatz_reps\n",
        "        self.num_qubits = num_qubits\n",
        "        self.circuit = QuantumCircuit(num_qubits)\n",
        "\n",
        "        # Parameters to be optimized\n",
        "        self.parameters = self._setup_parameters()\n",
        "\n",
        "        # Create the circuit\n",
        "        self.build_circuit()\n",
        "\n",
        "    def _setup_parameters(self):\n",
        "        \"\"\"\n",
        "        Sets the parameters to be optimized for the circuit.\n",
        "        \"\"\"\n",
        "        params = {}\n",
        "        for i in range(self.ansatz_reps):\n",
        "            params[f'x_{2*i}'] = Parameter(f'x_{2*i}')\n",
        "            params[f'x_{2*i+1}'] = Parameter(f'x_{2*i+1}')\n",
        "            params[f'theta_{i}'] = Parameter(f'theta_{i}')\n",
        "            params[f'phi_{i}'] = Parameter(f'phi_{i}')\n",
        "            params[f'g_{i}'] = Parameter(f'g_{i}')\n",
        "        return params\n",
        "\n",
        "    def _apply_ansatz_layer(self, rep):\n",
        "        \"\"\"\n",
        "        Applies a single ansatz layer to the circuit.\n",
        "        \"\"\"\n",
        "        x_0 = self.parameters[f'x_{2*rep}']\n",
        "        x_1 = self.parameters[f'x_{2*rep+1}']\n",
        "        theta_0 = self.parameters[f'theta_{rep}']\n",
        "        phi_0 = self.parameters[f'phi_{rep}']\n",
        "        g_0 = self.parameters[f'g_{rep}']\n",
        "\n",
        "        self.circuit.rz(x_0, 0)\n",
        "        self.circuit.ry(theta_0, 1)\n",
        "        self.circuit.ry(phi_0, 2)\n",
        "        self.circuit.rx(g_0, 3)\n",
        "\n",
        "        if self.ansatz == 0:\n",
        "            self.circuit.cx(1, 2)\n",
        "            self.circuit.cx(2, 3)\n",
        "            self.circuit.cx(3, 0)\n",
        "        elif self.ansatz == 1:\n",
        "            self.circuit.cx(3, 2)\n",
        "            self.circuit.cx(2, 1)\n",
        "            self.circuit.cx(1, 0)\n",
        "        elif self.ansatz == 2:\n",
        "            self.circuit.cx(1, 3)\n",
        "            self.circuit.cx(3, 2)\n",
        "            self.circuit.cx(2, 0)\n",
        "        else:\n",
        "            print(\"Invalid Ansatz\")\n",
        "\n",
        "        self.circuit.rz(x_1, 0)\n",
        "\n",
        "\n",
        "    def build_circuit(self):\n",
        "        \"\"\"\n",
        "        Builds the QNLNN circuit with the desired ansatz\n",
        "        and number of repetitions\n",
        "        \"\"\"\n",
        "        for rep in range(self.ansatz_reps):\n",
        "            self._apply_ansatz_layer(rep)\n",
        "\n",
        "\n",
        "    def circuit_parameters(self):\n",
        "        \"\"\"\n",
        "        Returns the set of parameters.\n",
        "        \"\"\"\n",
        "        return set(self.parameters.values())\n",
        "\n",
        "    def get_circuit(self):\n",
        "        \"\"\"\n",
        "        Returns the circuit.\n",
        "        \"\"\"\n",
        "        return self.circuit"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "tYgBwdSnOxnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit.visualization import circuit_drawer\n",
        "\n",
        "# Instantiate the circuit with ansatz 0\n",
        "circuit = QNLNetCircuit(ansatz=0, ansatz_reps=1)\n",
        "\n",
        "# Get the QuantumCircuit object\n",
        "qc = circuit.get_circuit()\n",
        "\n",
        "# Print the circuit\n",
        "print(qc)"
      ],
      "metadata": {
        "id": "Eqa29duglB6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit-machine-learning"
      ],
      "metadata": {
        "id": "r_2Hm6-f2jsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MULTICLASS CLASSIFICATION MODEL DEFINITION\n",
        "\n"
      ],
      "metadata": {
        "id": "CkpNfiIo6JZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import (\n",
        "    Module,\n",
        "    Conv2d,\n",
        "    Linear,\n",
        "    Dropout2d,\n",
        "    Flatten,\n",
        ")\n",
        "from torch import cat\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from qiskit import QuantumCircuit\n",
        "#from qiskit.circuit import Parameter\n",
        "from qiskit.circuit.library import ZFeatureMap\n",
        "from qiskit_machine_learning.utils import algorithm_globals\n",
        "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "from qiskit.quantum_info import Pauli, SparsePauliOp\n",
        "\n",
        "num_qubits = 4\n",
        "\n",
        "\n",
        "# Compose QNL-Net Mechanism with Feature Map\n",
        "def create_qnlnet_multiclass(feature_map_reps, ansatz , ansatz_reps):\n",
        "    \"\"\"\n",
        "    Compose QNL-Net Mechanism with Feature Map utilizing EstimatorQNN.\n",
        "\n",
        "    Returns:\n",
        "        Quantum non-local neural network.\n",
        "    \"\"\"\n",
        "    # Feature Map for Encoding\n",
        "    feature_map = ZFeatureMap(num_qubits, reps=feature_map_reps)\n",
        "\n",
        "    # QNL-Net circuit\n",
        "    qnlnet_instance = QNLNetCircuit(num_qubits=num_qubits, ansatz=ansatz, ansatz_reps=ansatz_reps)\n",
        "    qnlnet_circuit = qnlnet_instance.get_circuit()\n",
        "\n",
        "    qc = QuantumCircuit(num_qubits)\n",
        "    qc.compose(feature_map, inplace=True)\n",
        "    qc.compose(qnlnet_circuit, inplace=True)\n",
        "\n",
        "    # EstimatorQNN Observable\n",
        "    pauli_z_qubit0 = Pauli('Z' + 'I' * (num_qubits - 1))\n",
        "    observable_0 = SparsePauliOp([pauli_z_qubit0])\n",
        "    pauli_z_qubit1 = Pauli('I' + 'Z' + 'I' * (num_qubits - 2))\n",
        "    observable_1 = SparsePauliOp([pauli_z_qubit1])\n",
        "\n",
        "    observables= [observable_0, observable_1]\n",
        "\n",
        "    # REMEMBER TO SET input_gradients=True FOR ENABLING HYBRID GRADIENT BACKPROP\n",
        "    qnlnet = EstimatorQNN(\n",
        "        circuit=qc,\n",
        "        observables=observables,\n",
        "        input_params=feature_map.parameters,\n",
        "        weight_params=qnlnet_instance.circuit_parameters(),\n",
        "        input_gradients=True,\n",
        "    )\n",
        "\n",
        "    return qnlnet\n",
        "\n",
        "# Define torch Module for Hybrid CNN-QNL-Net\n",
        "class MulticlassHybridCNNQNLNet(Module):\n",
        "    \"\"\"\n",
        "    HybridCNNQNLNN is a hybrid quantum-classical convolutional neural network\n",
        "    with QNLNN.\n",
        "\n",
        "    Args:\n",
        "        qnlnet: Quantum non-local neural network.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, qnlnet):\n",
        "        super().__init__()\n",
        "        self.conv1 = Conv2d(3, 6, kernel_size=5)\n",
        "        self.conv2 = Conv2d(6, 12, kernel_size=5)\n",
        "        self.dropout = Dropout2d()\n",
        "        self.flatten = Flatten()\n",
        "        self.fc1 = Linear(300, 128)\n",
        "        self.fc2 = Linear(128, num_qubits)\n",
        "\n",
        "        # Apply torch connector, weights chosen\n",
        "        # uniformly at random from interval [-1,1].\n",
        "        self.qnlnet = TorchConnector(qnlnet)\n",
        "\n",
        "        # output from QNLNN\n",
        "        self.output_layer = Linear(2, 4) #four class classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the HybridCNNQNLNet.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor.\n",
        "\n",
        "        Returns:\n",
        "            x (torch.Tensor): Output tensor.\n",
        "        \"\"\"\n",
        "        # CNN\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout(x)\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # QNLNN\n",
        "        x = self.qnlnet.forward(x)\n",
        "\n",
        "        # Post-QNL-Net Classical Linear layer\n",
        "        x = self.output_layer(x)\n",
        "\n",
        "        #x = cat((x, 1 - x), -1)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "sN4OHHJFpFVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BINARY CLASSIFICATION MODEL DEFINITION"
      ],
      "metadata": {
        "id": "qTusLOlm6TyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import (\n",
        "    Module,\n",
        "    Conv2d,\n",
        "    Linear,\n",
        "    Dropout2d,\n",
        "    Flatten,\n",
        ")\n",
        "from torch import cat\n",
        "import torch.nn.functional as F\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.circuit.library import ZFeatureMap\n",
        "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
        "from qiskit.quantum_info import SparsePauliOp, Pauli\n",
        "\n",
        "\n",
        "num_qubits = 4\n",
        "output_shape = 2  # Number of classes\n",
        "\n",
        "\n",
        "# Compose QNL-Net Mechanism with Feature Map\n",
        "def create_qnlnet(feature_map_reps, ansatz, ansatz_reps):\n",
        "    \"\"\"\n",
        "    Compose QNL-Net Mechanism with Feature Map utilizing EstimatorQNN.\n",
        "\n",
        "    Returns:\n",
        "        Quantum non-local neural network.\n",
        "    \"\"\"\n",
        "    # Feature Map for Encoding\n",
        "    feature_map = ZFeatureMap(num_qubits, reps=feature_map_reps)\n",
        "\n",
        "    # QNL-Net circuit\n",
        "    qnlnet_instance = QNLNetCircuit(num_qubits=num_qubits, ansatz=ansatz, ansatz_reps=ansatz_reps)\n",
        "    qnlnet_circuit = qnlnet_instance.get_circuit()\n",
        "\n",
        "    qc = QuantumCircuit(num_qubits)\n",
        "    qc.compose(feature_map, inplace=True)\n",
        "    qc.compose(qnlnet_circuit, inplace=True)\n",
        "\n",
        "    # EstimatorQNN Observable\n",
        "    pauli_z_qubit0 = Pauli('Z' + 'I' * (num_qubits - 1))\n",
        "    observable = SparsePauliOp(pauli_z_qubit0)\n",
        "\n",
        "    # REMEMBER TO SET input_gradients=True FOR ENABLING HYBRID GRADIENT BACKPROP\n",
        "    qnlnet = EstimatorQNN(\n",
        "        circuit=qc,\n",
        "        observables=observable,\n",
        "        input_params=feature_map.parameters,\n",
        "        weight_params=qnlnet_instance.circuit_parameters(),\n",
        "        input_gradients=True,\n",
        "    )\n",
        "\n",
        "    return qnlnet\n",
        "\n",
        "\n",
        "# Define torch Module for Hybrid CNN-QNL-Net\n",
        "class HybridCNNQNLNet(Module):\n",
        "    \"\"\"\n",
        "    HybridCNNQNLNN is a hybrid quantum-classical convolutional neural network\n",
        "    with QNLNN.\n",
        "\n",
        "    Args:\n",
        "        qnlnet: Quantum non-local neural network.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, qnlnet):\n",
        "        super().__init__()\n",
        "        self.conv1 = Conv2d(3, 6, kernel_size=5)\n",
        "        self.conv2 = Conv2d(6, 12, kernel_size=5)\n",
        "        self.dropout = Dropout2d()\n",
        "        self.flatten = Flatten()\n",
        "        self.fc1 = Linear(300, 128)\n",
        "        self.fc2 = Linear(128, num_qubits)  # 4 inputs to QNL-Net\n",
        "\n",
        "        # Apply torch connector, weights chosen\n",
        "        # uniformly at random from interval [-1,1].\n",
        "        self.qnlnet = TorchConnector(qnlnet)\n",
        "\n",
        "        # output from QNLNN\n",
        "        self.output_layer = Linear(1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the HybridCNNQNLNet.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor.\n",
        "\n",
        "        Returns:\n",
        "            x (torch.Tensor): Output tensor.\n",
        "        \"\"\"\n",
        "        # CNN\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout(x)\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # QNLNN\n",
        "        x = self.qnlnet.forward(x)\n",
        "\n",
        "        # Post-QNL-Net Classical Linear layer\n",
        "        x = self.output_layer(x)\n",
        "\n",
        "        x = cat((x, 1 - x), -1)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "K61SyZqqQbyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MODEL INIZIALIZATION"
      ],
      "metadata": {
        "id": "-3Votu8oqcnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torch import manual_seed, no_grad, device\n",
        "from torch.nn import NLLLoss\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchsummary import summary\n",
        "import csv\n",
        "\n",
        "ansatz = 1\n",
        "feature_map_reps = 1\n",
        "ansatz_reps = 1\n",
        "num_epochs = 10\n",
        "lr = 3e-4\n",
        "if multiclassClassification==0:\n",
        "  qnlnn = create_qnlnet(feature_map_reps, ansatz, ansatz_reps)\n",
        "  model = HybridCNNQNLNet(qnlnn)\n",
        "if multiclassClassification==1:\n",
        "  qnlnn = create_qnlnet_multiclass(feature_map_reps, ansatz, ansatz_reps)\n",
        "  model = MulticlassHybridCNNQNLNet(qnlnn)\n",
        "\n",
        "# Check CUDA availability and move model to GPU if available\n",
        "if torch.cuda.is_available():\n",
        "    device_ = device(\"cuda\")\n",
        "else:\n",
        "    device_ = device(\"cpu\")\n",
        "model.to(device_) # Move the model to the selected device\n"
      ],
      "metadata": {
        "id": "LoWaK_Mg1Jmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SETUP MULTICLASS DATASET"
      ],
      "metadata": {
        "id": "GnKDfELbqxvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if multiclassClassification == 1:\n",
        "  # Set train shuffle seed (for reproducibility)\n",
        "  manual_seed(239)\n",
        "\n",
        "  batch_size = 10\n",
        "  n_train_samples = 50000\n",
        "  n_test_samples = 10000\n",
        "\n",
        "  # Use pre-defined torchvision function to load CIFAR10 data\n",
        "  train_dataset = datasets.CIFAR10(\n",
        "      root=\"./data\",\n",
        "      train=True,\n",
        "      download=True,\n",
        "      transform=transforms.Compose([transforms.ToTensor(),\n",
        "                                    transforms.Normalize(\n",
        "                                        (0.4915, 0.4823, .4468),\n",
        "                                        (0.2470, 0.2435, 0.2616)\n",
        "                                    )])\n",
        "  )\n",
        "\n",
        "  test_dataset = datasets.CIFAR10(\n",
        "      root=\"./data\",\n",
        "      train=False,\n",
        "      download=True,\n",
        "      transform=transforms.Compose([transforms.ToTensor(),\n",
        "                                    transforms.Normalize(\n",
        "                                        (0.4915, 0.4823, .4468),\n",
        "                                        (0.2470, 0.2435, 0.2616)\n",
        "                                    )])\n",
        "  )\n",
        "\n",
        "  train_idx = np.append(\n",
        "        np.where(np.array(train_dataset.targets) == 0)[0][:n_train_samples],\n",
        "        np.append(\n",
        "            np.where(np.array(train_dataset.targets) == 1)[0][:n_train_samples],\n",
        "              np.append(\n",
        "                np.where(np.array(train_dataset.targets) == 2)[0][:n_train_samples],\n",
        "                np.where(np.array(train_dataset.targets) == 8)[0][:n_train_samples]\n",
        "            )\n",
        "        )\n",
        "  )\n",
        "\n",
        "  test_idx = np.append(\n",
        "      np.where(np.array(test_dataset.targets) == 0)[0][:n_test_samples],\n",
        "      np.append(\n",
        "          np.where(np.array(test_dataset.targets) == 1)[0][:n_test_samples],\n",
        "          np.append(\n",
        "              np.where(np.array(test_dataset.targets) == 2)[0][:n_test_samples],\n",
        "              np.where(np.array(test_dataset.targets) == 8)[0][:n_test_samples]\n",
        "              )\n",
        "          )\n",
        "      )\n",
        "\n",
        "  train_dataset.data = train_dataset.data[train_idx]\n",
        "  train_dataset.targets = np.array(train_dataset.targets)[train_idx]\n",
        "\n",
        "  test_dataset.data = test_dataset.data[test_idx]\n",
        "  test_dataset.targets = np.array(test_dataset.targets)[test_idx]\n",
        "\n",
        "  # Encode desired classes as targets\n",
        "  train_dataset.targets[train_dataset.targets == 0] = 2\n",
        "  train_dataset.targets[train_dataset.targets == 1] = 3\n",
        "  train_dataset.targets[train_dataset.targets == 2] = 0\n",
        "  train_dataset.targets[train_dataset.targets == 8] = 1\n",
        "\n",
        "  test_dataset.targets[test_dataset.targets == 0] = 2\n",
        "  test_dataset.targets[test_dataset.targets == 1] = 3\n",
        "  test_dataset.targets[test_dataset.targets == 2] = 0\n",
        "  test_dataset.targets[test_dataset.targets == 8] = 1\n",
        "\n",
        "  # Define torch dataloaders\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  # Print training and testing dataset info\n",
        "  print(train_dataset)\n",
        "  print(test_dataset)\n",
        "  print(\"================================================================\")\n"
      ],
      "metadata": {
        "id": "G3rSAH-G2kWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SETUP BINARY DATASET"
      ],
      "metadata": {
        "id": "AQ7XHy62rBlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if multiclassClassification == 0:\n",
        "  # Set train shuffle seed (for reproducibility)\n",
        "  manual_seed(239)\n",
        "\n",
        "  batch_size = 1\n",
        "  n_train_samples = 50000\n",
        "  n_test_samples = 10000\n",
        "\n",
        "  # Use pre-defined torchvision function to load CIFAR10 data\n",
        "  train_dataset = datasets.CIFAR10(\n",
        "      root=\"./data\",\n",
        "      train=True,\n",
        "      download=True,\n",
        "      transform=transforms.Compose([transforms.ToTensor(),\n",
        "                                    transforms.Normalize(\n",
        "                                        (0.4915, 0.4823, .4468),\n",
        "                                        (0.2470, 0.2435, 0.2616)\n",
        "                                    )])\n",
        "  )\n",
        "\n",
        "  test_dataset = datasets.CIFAR10(\n",
        "      root=\"./data\",\n",
        "      train=False,\n",
        "      download=True,\n",
        "      transform=transforms.Compose([transforms.ToTensor(),\n",
        "                                    transforms.Normalize(\n",
        "                                        (0.4915, 0.4823, .4468),\n",
        "                                        (0.2470, 0.2435, 0.2616)\n",
        "                                    )])\n",
        "  )\n",
        "\n",
        "  # Filter out labels\n",
        "  train_idx = np.append(\n",
        "      np.where(np.array(train_dataset.targets) == 2)[0][:n_train_samples],\n",
        "      np.where(np.array(train_dataset.targets) == 8)[0][:n_train_samples]\n",
        "  )\n",
        "\n",
        "  test_idx = np.append(\n",
        "      np.where(np.array(test_dataset.targets) == 2)[0][:n_test_samples],\n",
        "      np.where(np.array(test_dataset.targets) == 8)[0][:n_test_samples]\n",
        "  )\n",
        "\n",
        "  train_dataset.data = train_dataset.data[train_idx]\n",
        "  train_dataset.targets = np.array(train_dataset.targets)[train_idx]\n",
        "\n",
        "  test_dataset.data = test_dataset.data[test_idx]\n",
        "  test_dataset.targets = np.array(test_dataset.targets)[test_idx]\n",
        "\n",
        "  # Encode desired classes as targets\n",
        "  train_dataset.targets[train_dataset.targets == 2] = 0\n",
        "  train_dataset.targets[train_dataset.targets == 8] = 1\n",
        "\n",
        "  test_dataset.targets[test_dataset.targets == 2] = 0\n",
        "  test_dataset.targets[test_dataset.targets == 8] = 1\n",
        "\n",
        "  # Define torch dataloaders\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  # Print training and testing dataset info\n",
        "  print(train_dataset)\n",
        "  print(test_dataset)\n",
        "  print(\"================================================================\")\n"
      ],
      "metadata": {
        "id": "AktiUVr8SXBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SET UP WANDB"
      ],
      "metadata": {
        "id": "aGfiC-y95uuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qU"
      ],
      "metadata": {
        "id": "NcESHUomS613"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "fndIRxuGS-ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"hybrid-cnn-qnlnet-cifar10\",\n",
        "           name=\"ansatz_{}_fmreps_{}_ansatzreps_{}_multiclass\".format(ansatz, feature_map_reps, ansatz_reps)\n",
        "           )\n",
        "wandb.config.ansatz = ansatz\n",
        "wandb.config.feature_map_reps = feature_map_reps\n",
        "wandb.config.ansatz_reps = ansatz_reps\n",
        "wandb.config.num_epochs = num_epochs\n",
        "wandb.config.lr = lr\n",
        "wandb.config.batch_size = batch_size"
      ],
      "metadata": {
        "id": "ZrYOrqd-TfJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TRAINING AND TESTING"
      ],
      "metadata": {
        "id": "JSozpbwBrKtr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
        "\n",
        "model.train()  # Set model to training mode\n",
        "\n",
        "epoch_data = []\n",
        "\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Training Progress\"):  # Wrap epoch loop with tqdm\n",
        "    total_loss = 0\n",
        "    correct_train = 0\n",
        "    total_train = len(train_dataset)\n",
        "\n",
        "    for data, target in tqdm(train_loader, desc=f\"Epoch {epoch + 1}\", leave=False):  # Wrap data loader with tqdm\n",
        "        # Move data and target to the same device as the model\n",
        "        data, target = data.to(device_), target.to(device_)\n",
        "\n",
        "        optimizer.zero_grad()  # Initialize gradient\n",
        "        output = model(data)  # Forward pass\n",
        "        loss = loss_func(output, target)  # Calculate loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Optimize weights\n",
        "        total_loss += loss.item() * data.size(0)  # Accumulate loss\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        correct_train += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    epoch_loss = total_loss / total_train\n",
        "    epoch_accuracy_train = correct_train / total_train\n",
        "\n",
        "    # Testing\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    correct_test = 0\n",
        "    total_test = len(test_dataset)\n",
        "\n",
        "    with no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device_), target.to(device_)\n",
        "\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct_test += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_accuracy = correct_test / total_test\n",
        "\n",
        "    epoch_data.append((epoch + 1, epoch_loss, epoch_accuracy_train, test_accuracy))\n",
        "\n",
        "    wandb.log({\"Epoch\": epoch + 1, \"Train Loss\": epoch_loss, \"Train Accuracy\": epoch_accuracy_train, \"Test Accuracy\": test_accuracy})\n",
        "\n",
        "    print(\"Epoch {}: Train Loss: {:.4f}; Train Accuracy: {:.4f}; Test Accuracy: {:.4f}\".format(\n",
        "        epoch + 1, epoch_loss, epoch_accuracy_train, test_accuracy))\n",
        "\n",
        "    model.train()  # Set model back to training mode\n",
        "    scheduler.step()  # Adjust learning rate for next epoch\n",
        "print(\"================================================================\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KcCZRCFp0o9Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}